{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9be4a36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import webbrowser\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42d974f",
   "metadata": {},
   "source": [
    "# I. Définition des fonctions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3c46bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vidéo callback\n",
    "\n",
    "def onMouse(event, x, y, flags, links):\n",
    "    \"\"\"\n",
    "    For each frame : \n",
    "    When mouse inside, display clickable area in image\n",
    "    Open link in web browser when image clicked\n",
    "    \n",
    "    input : \n",
    "        x,y : position of the mouse on the image \n",
    "        links : Links object. Allows  to make the image interactive\n",
    "\n",
    "    \"\"\"\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        #check if item has been clicked\n",
    "        links.itemClicked(x,y) \n",
    "        \n",
    "    if event == cv2.EVENT_MOUSEMOVE: \n",
    "        # check if mouse inside a clickable area\n",
    "        links.displayArea(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0162b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def itemsExtraction(model, path='advertising.mp4'):\n",
    "    \"\"\"\n",
    "    for each frame, model detect clothes and return their positions\n",
    "    \"\"\"\n",
    "\n",
    "    adVideo = cv2.VideoCapture(path)\n",
    "    #check if vidéo \n",
    "    if (adVideo.isOpened()== False): \n",
    "      print(\"Error opening video stream or file\")\n",
    "\n",
    "\n",
    "    frame_index = 0\n",
    "    data = { }\n",
    "    # Read until video is completed\n",
    "    while(adVideo.isOpened()):\n",
    "      # Capture frame-by-frame\n",
    "      ret, frame = adVideo.read()\n",
    "      if ret == True:\n",
    "\n",
    "        #detect clothes\n",
    "        results = model(frame)   \n",
    "        if results.pandas().xyxy[0].shape[0] == 0 :\n",
    "            #if no clothes detetected return empty value \n",
    "            d = {'xmin': [0], 'ymin': [0], 'xmax': [0], 'ymax': [0], 'confidence': [0], 'class': [0], 'name': [\" \"]}\n",
    "            data[frame_index] = np.array(pd.DataFrame(data=d))[0]\n",
    "        else : \n",
    "            #return model result => for each frame only detect one clothes\n",
    "            data[frame_index] = np.array(results.pandas().xyxy[0].iloc[results.pandas().xyxy[0]['confidence'].argmax()])\n",
    "        frame_index += 1\n",
    "\n",
    "\n",
    "\n",
    "      else: \n",
    "        break\n",
    "\n",
    "    # When everything done, release the video capture object\n",
    "\n",
    "    adVideo.release()\n",
    "    if (adVideo.isOpened()== False): \n",
    "      print(\"Vidéo closed\")\n",
    "\n",
    "    # Closes all the frames\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c91019fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Links:\n",
    "    \"\"\"\n",
    "    Class that makes video clickable\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, data, items):\n",
    "        \"\"\"\n",
    "        data : clothes bbox for each frame. Result of itemsExtraction function\n",
    "        items : links associated with clothes\n",
    "        frame_index : index of the actual frame\n",
    "        display :bool to display area'border only when mouse inside\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.items = items\n",
    "        self.frame_index = 0\n",
    "        self.display = False\n",
    "            \n",
    "            \n",
    "\n",
    "               \n",
    "    def itemClicked(self,x,y): \n",
    "        \n",
    "        \"\"\"\n",
    "        method who detect which clothes has been clicked, and open the corresponding link\n",
    "        \"\"\"\n",
    "        \n",
    "        #check if mouse inside the area : if inside open the link\n",
    "        if( (x > self.data[self.frame_index][0]) and (x < self.data[self.frame_index][2])\n",
    "           and (y > self.data[self.frame_index][1]) and (y < self.data[self.frame_index][3])):\n",
    "#                 webbrowser.open(items[self.data[frame][6]])\n",
    "              webbrowser.open('https://fr.shein.com/Men-Solid-Notched-Neck-Tee-p-9079332-cat-1978.html?url_from=fradplasm2112064364522856M_GPM&cid=16923873116&setid=&adid=&pf=GOOGLE&gclid=CjwKCAjwwo-WBhAMEiwAV4dybdFPPKeAXk-t6suc5z_-2aqXyCbqWfYIHA3xfRMTYOlTExBxcQFPSxoC8IwQAvD_BwE')\n",
    "                \n",
    "                \n",
    "    def displayArea(self, x, y):\n",
    "        \"\"\"\n",
    "        method who detect if mouse in clickable area. If inside, display border of this area as insight for the customer he \n",
    "        can click\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "            \n",
    "        if((x > self.data[self.frame_index][0]) and (x < self.data[self.frame_index][2])\n",
    "           and (y > self.data[self.frame_index][1]) and (y < self.data[self.frame_index][3])):\n",
    "\n",
    "            if(not self.display):    \n",
    "                # if mouse inside area, display the area\n",
    "                self.display = True\n",
    "\n",
    "        else : \n",
    "            if (self.display):\n",
    "                # if mouse quit area stop displaying the area\n",
    "                self.display = False\n",
    "        \n",
    "        \n",
    "    def incrementFrameIndex(self): \n",
    "        \n",
    "        self.frame_index += 1\n",
    "        \n",
    "    \n",
    "    def getItems(self):\n",
    "        #get position of clothes for the current frame\n",
    "        \n",
    "        return (self.data[self.frame_index])\n",
    "       \n",
    "                \n",
    "    def clearLinks(self): \n",
    "        #clear the object\n",
    "        self.data = {}\n",
    "        self.items = {}\n",
    "        self.frame_index = 0\n",
    "        self.display = False\n",
    "        \n",
    "    def reset(self): \n",
    "        #reset the object to be use again\n",
    "        self.frame_index = 0\n",
    "        self.display = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "632c8e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def data_process(dataset, distance=5, windowAvgSize=5):\n",
    "    \"\"\"\n",
    "    Process the data. Fills frames that have no items when they should have them.\n",
    "    Average of the bboxes among the frames to avoid a too important movement of the bboxes.\n",
    "    \n",
    "    dataset : bbox clothing for each image. Result of the itemsExtraction function\n",
    "    distance : maximum abnormal distance of frames without elements. If the distance is smaller, we fill the blanks. \n",
    "    If the distance is greater we consider it to be a frames sequence without clothes.\n",
    "    windowAVgSize : Size of the window to average the bboxes among\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    data = dataset.copy()\n",
    "    \n",
    "    \n",
    "    #check for undetected clothes. \n",
    "    for index in range(1,len(data)-1) : \n",
    "        \n",
    "        #detect frame without items\n",
    "        if np.sum(data[index][:4] == 0):\n",
    "            space_index = 1\n",
    "            \n",
    "            #check the length of the frame sequence without items\n",
    "            while np.sum(data[space_index + index][:4] == 0) and space_index + index < len(data) - 2:\n",
    "                space_index += 1\n",
    "                               \n",
    "            #if sequence of frames whitout items short enough and items detected before and after are the same, fill \n",
    "            #the blanks\n",
    "            if space_index <= distance and np.mean(np.std(np.append(data[index - 1][:4][None, :]\n",
    "             ,data[index + space_index][:4][None, :], axis=0).astype('float64'), axis = 0)) < 10:\n",
    "\n",
    "                for k in range(space_index):\n",
    "                    data[index + k] = data[index - 1]\n",
    "                    \n",
    "    \n",
    "    #average on sequence of frames of similar items\n",
    "    for index in range(0, len(data) - windowAvgSize) : \n",
    "        \n",
    "        dataNeibhor = data[index][:4][None, :]\n",
    "        \n",
    "        for k in range(1, windowAvgSize) : \n",
    "            \n",
    "            dataNeibhor = np.append(dataNeibhor, data[index + k][:4][None, :], axis=0)\n",
    "        \n",
    "        #check if similar items\n",
    "        if np.mean(np.std(dataNeibhor.astype('float64'), axis = 0)) < 10:\n",
    "\n",
    "            data[index][0] = np.mean(dataNeibhor, axis=0)[0]\n",
    "            data[index][1] = np.mean(dataNeibhor, axis=0)[1]\n",
    "            data[index][2] = np.mean(dataNeibhor, axis=0)[2]\n",
    "            data[index][3] = np.mean(dataNeibhor, axis=0)[3]\n",
    "        \n",
    "            \n",
    "        \n",
    "\n",
    "                \n",
    "          \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8067ec6b",
   "metadata": {},
   "source": [
    "# II. Proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76872b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2022-5-20 Python-3.9.12 torch-1.11.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 213 layers, 7144975 parameters, 0 gradients, 16.2 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "#import model \n",
    "\n",
    "model = torch.hub.load('../iaApi/yolov5', 'custom', path='../iaApi/models/Fashion_Datasets_50_labels_V1.pt', source='local')\n",
    "model.conf = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a92772c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data and data manipulation\n",
    "\n",
    "# data = itemsExtraction(model, path='advertising.mp4')\n",
    "# data = data_process(data)\n",
    "\n",
    "# fileObj = open('data.obj', 'wb')\n",
    "# pickle.dump(data,fileObj)\n",
    "# fileObj.close()\n",
    "\n",
    "\n",
    "fileObj = open('data.obj', 'rb')\n",
    "data = pickle.load(fileObj)\n",
    "fileObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e71069a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = Links(data, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62766d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vidéo closed\n"
     ]
    }
   ],
   "source": [
    "#main : application demo\n",
    "\n",
    "\n",
    "adVideo = cv2.VideoCapture('advertising.mp4')\n",
    "if (adVideo.isOpened()== False): \n",
    "  print(\"Error opening video stream or file\")\n",
    "\n",
    "\n",
    "color = (255, 0, 0)\n",
    "thickness = 2\n",
    "links = Links(data, {})\n",
    "\n",
    "\n",
    "# Read until video is completed\n",
    "while(adVideo.isOpened()):\n",
    "  # Capture frame-by-frame\n",
    "  ret, frame = adVideo.read()\n",
    "  if ret == True:\n",
    "    \n",
    "    # Window name in which image is displayed\n",
    "    window_name = 'Image'\n",
    "\n",
    "   \n",
    "    \n",
    "\n",
    "   \n",
    "    #show clickable are\n",
    "    if(links.display):\n",
    "        itemsData = links.getItems()\n",
    "        frame = cv2.rectangle(frame, (int(itemsData[0]),int(itemsData[1])),\n",
    "                              (int(itemsData[2]),int(itemsData[3])), color,thickness)\n",
    "\n",
    "    \n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Frame',frame)   \n",
    "    cv2.setMouseCallback('Frame', onMouse, links)\n",
    "    \n",
    "    links.incrementFrameIndex()\n",
    "\n",
    "    # Press Q on keyboard to  exit\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "      break\n",
    "    \n",
    "\n",
    "\n",
    "  # Break the loop\n",
    "  else: \n",
    "    break\n",
    "\n",
    "# When everything done, release the video capture object\n",
    "adVideo.release()\n",
    "if (adVideo.isOpened()== False): \n",
    "  print(\"Vidéo closed\")\n",
    "\n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()\n",
    "links.reset()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
